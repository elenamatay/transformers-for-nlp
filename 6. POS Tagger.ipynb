{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1fa6b2-23eb-46a5-8c5d-b3ad9989bceb",
   "metadata": {},
   "source": [
    "# 6. POS Tagger\n",
    "\n",
    "POS Tagging stands for Part-of-Speech tagging (aka PoS tagging or POST), also called grammatical tagging, and is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context. More info [here](https://en.wikipedia.org/wiki/Part-of-speech_tagging).\n",
    "\n",
    "Same concept as in NER, but with our custom data to be imported in JSON format, and with custom labels (not NER, but other strings to classify our words in)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4d199-7f2a-4735-bf9b-e1152f09db8c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33b2f5a-6eb8-4718-91f2-fe848d13d3ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --q transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628bb9c7-399d-4f63-9a94-fc49cbceb9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments, Trainer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87602e84-6fde-48f7-a805-1dd4f6f96c61",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e177c1-f9d5-4b10-a9f2-b9fb8c7a1342",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b18fe1-9eed-43bc-97ca-4cb0b08d14e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = brown.tagged_sents(tagset='universal')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6c1d8f-a40e-43a5-8275-903fb9c7aa8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for sentence_tag_pairs in corpus:\n",
    "    tokens = []\n",
    "    target = []\n",
    "    for token, tag in sentence_tag_pairs:\n",
    "        tokens.append(token)\n",
    "        target.append(tag)\n",
    "    inputs.append(tokens)\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1f21ea-7913-4137-9853-109f0071385e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save data to json format\n",
    "with open('data.json', 'w') as f:\n",
    "    for x, y in zip(inputs, targets):\n",
    "        j = {'inputs': x, 'targets': y}\n",
    "        s = json.dumps(j)\n",
    "        f.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd50def-4122-4ffb-a6d8-b04663d92da9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5879197c5cb4c689b5d908f8c72ed69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files='data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd527185-f8ef-4c85-93ae-2d31390f4a16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'targets'],\n",
       "        num_rows: 57340\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef2809d9-f840-4148-9a49-00b5e074851b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'targets'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = data[\"train\"].shuffle(seed=42).select(range(20_000))\n",
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f60023f-89ec-42a4-993a-947c79e06cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = small.train_test_split(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b2f74b9-4e14-4bc7-9224-992e9372d159",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': ['Ulyate',\n",
       "  'and',\n",
       "  'Kearton',\n",
       "  'climbed',\n",
       "  'on',\n",
       "  'toward',\n",
       "  'the',\n",
       "  'sound',\n",
       "  'of',\n",
       "  'the',\n",
       "  'barking',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dogs',\n",
       "  'and',\n",
       "  'the',\n",
       "  'sporadic',\n",
       "  'roaring',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lion',\n",
       "  ',',\n",
       "  'till',\n",
       "  'they',\n",
       "  'came',\n",
       "  ',',\n",
       "  'out',\n",
       "  'of',\n",
       "  'breath',\n",
       "  ',',\n",
       "  'to',\n",
       "  'the',\n",
       "  'crest',\n",
       "  ',',\n",
       "  'and',\n",
       "  'peering',\n",
       "  'through',\n",
       "  'the',\n",
       "  'branches',\n",
       "  'of',\n",
       "  'a',\n",
       "  'bush',\n",
       "  ',',\n",
       "  'this',\n",
       "  'is',\n",
       "  'what',\n",
       "  'Ulyate',\n",
       "  'saw',\n",
       "  ':',\n",
       "  'Jones',\n",
       "  'who',\n",
       "  'had',\n",
       "  'apparently',\n",
       "  '(',\n",
       "  'and',\n",
       "  'actually',\n",
       "  'had',\n",
       "  ')',\n",
       "  'ridden',\n",
       "  'up',\n",
       "  'the',\n",
       "  'nearly',\n",
       "  'impassable',\n",
       "  'hillside',\n",
       "  ',',\n",
       "  'sitting',\n",
       "  'calmly',\n",
       "  'on',\n",
       "  'his',\n",
       "  'horse',\n",
       "  'within',\n",
       "  'forty',\n",
       "  'feet',\n",
       "  'of',\n",
       "  'a',\n",
       "  'full-grown',\n",
       "  'young',\n",
       "  'lioness',\n",
       "  ',',\n",
       "  'who',\n",
       "  'was',\n",
       "  'crouched',\n",
       "  'on',\n",
       "  'a',\n",
       "  'flat',\n",
       "  'rock',\n",
       "  'and',\n",
       "  'seemed',\n",
       "  'just',\n",
       "  'about',\n",
       "  'to',\n",
       "  'charge',\n",
       "  'him',\n",
       "  ',',\n",
       "  'while',\n",
       "  'the',\n",
       "  'dogs',\n",
       "  'whirled',\n",
       "  'around',\n",
       "  'her',\n",
       "  '.'],\n",
       " 'targets': ['NOUN',\n",
       "  'CONJ',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'PRT',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'CONJ',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'ADP',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  '.',\n",
       "  'PRT',\n",
       "  'ADP',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'CONJ',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'DET',\n",
       "  'VERB',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  '.',\n",
       "  'NOUN',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'ADV',\n",
       "  '.',\n",
       "  'CONJ',\n",
       "  'ADV',\n",
       "  'VERB',\n",
       "  '.',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'ADV',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'VERB',\n",
       "  'ADV',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'NUM',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  '.',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'CONJ',\n",
       "  'VERB',\n",
       "  'ADV',\n",
       "  'ADV',\n",
       "  'PRT',\n",
       "  'VERB',\n",
       "  'PRON',\n",
       "  '.',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'PRON',\n",
       "  '.']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a28f4a1a-d09e-40b6-95c9-c71b246e5fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'targets': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29eebc87-a7e0-4ecb-beff-7b8f46e82043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map targets to ints\n",
    "target_set = set()\n",
    "for target in targets:\n",
    "    target_set = target_set.union(target)\n",
    "target_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d98cbed-3ff4-4c0b-bd56-5497514abf65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_list = list(target_set)\n",
    "id2label = {k: v for k, v in enumerate(target_list)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd6bbb-855c-41df-8885-3eb6d214281a",
   "metadata": {},
   "source": [
    "## Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e335509-3adc-473d-8b1a-ae62f72e93a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We could also try using BERT directly\n",
    "checkpoint = \"distilbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594f4f8-e058-40b3-a7de-512505000588",
   "metadata": {},
   "source": [
    "If we want to tokenize a doc that has been already split into words, like this one, we just need to pass in the argument `is_split_into_words=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b9582b0-bcfc-42e2-80f7-97c5fedd9e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 158, 25928, 1566, 1105, 26835, 9349, 1320, 5998, 1113, 1755, 1103, 1839, 1104, 1103, 26635, 1104, 1103, 6363, 1105, 1103, 188, 27695, 23041, 1104, 1103, 11160, 117, 6174, 1152, 1338, 117, 1149, 1104, 2184, 117, 1106, 1103, 13468, 117, 1105, 19205, 1194, 1103, 5020, 1104, 170, 13771, 117, 1142, 1110, 1184, 158, 25928, 1566, 1486, 131, 2690, 1150, 1125, 4547, 113, 1105, 2140, 1125, 114, 17698, 1146, 1103, 2212, 24034, 11192, 1895, 25068, 117, 2807, 13285, 1113, 1117, 3241, 1439, 5808, 1623, 1104, 170, 1554, 118, 4215, 1685, 11160, 5800, 117, 1150, 1108, 15062, 1113, 170, 3596, 2067, 1105, 1882, 1198, 1164, 1106, 2965, 1140, 117, 1229, 1103, 6363, 18370, 1213, 1123, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "t = tokenizer(data['train'][idx]['inputs'], is_split_into_words=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbd800c4-8968-4391-82ec-bd949f555cec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8297c8c-445f-47f2-a486-9f47a3549650",
   "metadata": {},
   "source": [
    "We see that although the tokenized data seemed like a dictionary, it's really a BatchEncoding object. This object has some useful object methods we can use, e.g. we can call tokens() to see the tokens represented in string format, instead of ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bc41c92-feb0-4676-8320-960543c8c1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'U',\n",
       " '##lya',\n",
       " '##te',\n",
       " 'and',\n",
       " 'Ke',\n",
       " '##art',\n",
       " '##on',\n",
       " 'climbed',\n",
       " 'on',\n",
       " 'toward',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'of',\n",
       " 'the',\n",
       " 'barking',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dogs',\n",
       " 'and',\n",
       " 'the',\n",
       " 's',\n",
       " '##poradic',\n",
       " 'roaring',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lion',\n",
       " ',',\n",
       " 'till',\n",
       " 'they',\n",
       " 'came',\n",
       " ',',\n",
       " 'out',\n",
       " 'of',\n",
       " 'breath',\n",
       " ',',\n",
       " 'to',\n",
       " 'the',\n",
       " 'crest',\n",
       " ',',\n",
       " 'and',\n",
       " 'peering',\n",
       " 'through',\n",
       " 'the',\n",
       " 'branches',\n",
       " 'of',\n",
       " 'a',\n",
       " 'bush',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'what',\n",
       " 'U',\n",
       " '##lya',\n",
       " '##te',\n",
       " 'saw',\n",
       " ':',\n",
       " 'Jones',\n",
       " 'who',\n",
       " 'had',\n",
       " 'apparently',\n",
       " '(',\n",
       " 'and',\n",
       " 'actually',\n",
       " 'had',\n",
       " ')',\n",
       " 'ridden',\n",
       " 'up',\n",
       " 'the',\n",
       " 'nearly',\n",
       " 'imp',\n",
       " '##ass',\n",
       " '##able',\n",
       " 'hillside',\n",
       " ',',\n",
       " 'sitting',\n",
       " 'calmly',\n",
       " 'on',\n",
       " 'his',\n",
       " 'horse',\n",
       " 'within',\n",
       " 'forty',\n",
       " 'feet',\n",
       " 'of',\n",
       " 'a',\n",
       " 'full',\n",
       " '-',\n",
       " 'grown',\n",
       " 'young',\n",
       " 'lion',\n",
       " '##ess',\n",
       " ',',\n",
       " 'who',\n",
       " 'was',\n",
       " 'crouched',\n",
       " 'on',\n",
       " 'a',\n",
       " 'flat',\n",
       " 'rock',\n",
       " 'and',\n",
       " 'seemed',\n",
       " 'just',\n",
       " 'about',\n",
       " 'to',\n",
       " 'charge',\n",
       " 'him',\n",
       " ',',\n",
       " 'while',\n",
       " 'the',\n",
       " 'dogs',\n",
       " 'whirled',\n",
       " 'around',\n",
       " 'her',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tokens() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5517e-c917-4ce9-aa0c-000284298cb1",
   "metadata": {},
   "source": [
    "We see the usual `[CLS]` and `[SEP]` [special tokens from BERT](https://www.neclab.eu/human-centric-ai-a-road-map-to-human-ai-collaboration/attending-to-future-tokens-for-bidirectional-sequence-generation#:~:text=The%20special%20tokens%20have%20specific,with%20the%20%5BMASK%5D%20token). Challenge: We have an input sequence and an output sequence, and their lengths vary. And we need to align the targets to the tokens, as tokens (words) have been split into sub-tokens (sub-words), but targets in NER are at the token (word) level.\n",
    "\n",
    "To fix this, we will **expand** our dataset, in the sense that for any word split into multiple tokens, we’ll assign the same target.\n",
    "\n",
    "But wait! What about special tokens from BERT (e.g. [CLS] and [SEP])? We need to create targets for those too.\n",
    "- Why do we need to do this? Transformers work that way. It’s similar to the RNN concept for the same task, we have (x(t)  h(t)  y(t), for all t), so we need all that tokens representation in their former and latter stage.\n",
    "- What value should we set for them? -100. Why? Because that’s the value that Hugging Face uses to know it needs to ignore them, not using them to update the model weights.\n",
    "\n",
    "We’ll need to write our own algorithm for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b334c0d0-edf1-4390-8f5b-e6e20c3179dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 75,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value of i indicates it's the i'th word in the input sentence (counting from 0)\n",
    "t.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74e40ce1-467a-4b28-9b7b-45605937eb36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def align_targets(labels, word_ids):\n",
    "    aligned_labels = []\n",
    "    for word in word_ids:\n",
    "        if word is None:         # token like [CLS]\n",
    "            label = -100\n",
    "        else:                    # it's a real word\n",
    "            label = label2id[labels[word]]\n",
    "\n",
    "        # add the label \n",
    "        aligned_labels.append(label)\n",
    "\n",
    "    return aligned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfa86e8b-2e50-40a4-a720-40853a90612f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 10,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 11,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 10,\n",
       " 2,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 10,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 11,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 4,\n",
       " 11,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 11,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 10,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 11,\n",
       " 9,\n",
       " 5,\n",
       " -100]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try our function\n",
    "labels = data['train'][idx]['targets']\n",
    "word_ids = t.word_ids()\n",
    "aligned_targets = align_targets(labels, word_ids)\n",
    "aligned_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d48ef12d-5011-45ff-b9d6-759d8d53ed37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\tNone\n",
      "U\tNOUN\n",
      "##lya\tNOUN\n",
      "##te\tNOUN\n",
      "and\tCONJ\n",
      "Ke\tNOUN\n",
      "##art\tNOUN\n",
      "##on\tNOUN\n",
      "climbed\tVERB\n",
      "on\tPRT\n",
      "toward\tADP\n",
      "the\tDET\n",
      "sound\tNOUN\n",
      "of\tADP\n",
      "the\tDET\n",
      "barking\tNOUN\n",
      "of\tADP\n",
      "the\tDET\n",
      "dogs\tNOUN\n",
      "and\tCONJ\n",
      "the\tDET\n",
      "s\tADJ\n",
      "##poradic\tADJ\n",
      "roaring\tNOUN\n",
      "of\tADP\n",
      "the\tDET\n",
      "lion\tNOUN\n",
      ",\t.\n",
      "till\tADP\n",
      "they\tPRON\n",
      "came\tVERB\n",
      ",\t.\n",
      "out\tPRT\n",
      "of\tADP\n",
      "breath\tNOUN\n",
      ",\t.\n",
      "to\tADP\n",
      "the\tDET\n",
      "crest\tNOUN\n",
      ",\t.\n",
      "and\tCONJ\n",
      "peering\tVERB\n",
      "through\tADP\n",
      "the\tDET\n",
      "branches\tNOUN\n",
      "of\tADP\n",
      "a\tDET\n",
      "bush\tNOUN\n",
      ",\t.\n",
      "this\tDET\n",
      "is\tVERB\n",
      "what\tDET\n",
      "U\tNOUN\n",
      "##lya\tNOUN\n",
      "##te\tNOUN\n",
      "saw\tVERB\n",
      ":\t.\n",
      "Jones\tNOUN\n",
      "who\tPRON\n",
      "had\tVERB\n",
      "apparently\tADV\n",
      "(\t.\n",
      "and\tCONJ\n",
      "actually\tADV\n",
      "had\tVERB\n",
      ")\t.\n",
      "ridden\tVERB\n",
      "up\tADP\n",
      "the\tDET\n",
      "nearly\tADV\n",
      "imp\tADJ\n",
      "##ass\tADJ\n",
      "##able\tADJ\n",
      "hillside\tNOUN\n",
      ",\t.\n",
      "sitting\tVERB\n",
      "calmly\tADV\n",
      "on\tADP\n",
      "his\tDET\n",
      "horse\tNOUN\n",
      "within\tADP\n",
      "forty\tNUM\n",
      "feet\tNOUN\n",
      "of\tADP\n",
      "a\tDET\n",
      "full\tADJ\n",
      "-\tADJ\n",
      "grown\tADJ\n",
      "young\tADJ\n",
      "lion\tNOUN\n",
      "##ess\tNOUN\n",
      ",\t.\n",
      "who\tPRON\n",
      "was\tVERB\n",
      "crouched\tVERB\n",
      "on\tADP\n",
      "a\tDET\n",
      "flat\tADJ\n",
      "rock\tNOUN\n",
      "and\tCONJ\n",
      "seemed\tVERB\n",
      "just\tADV\n",
      "about\tADV\n",
      "to\tPRT\n",
      "charge\tVERB\n",
      "him\tPRON\n",
      ",\t.\n",
      "while\tADP\n",
      "the\tDET\n",
      "dogs\tNOUN\n",
      "whirled\tVERB\n",
      "around\tADP\n",
      "her\tPRON\n",
      ".\t.\n",
      "[SEP]\tNone\n"
     ]
    }
   ],
   "source": [
    "aligned_labels = [id2label[i] if i >= 0 else None for i in aligned_targets]\n",
    "for x, y in zip(t.tokens(), aligned_labels):\n",
    "    print(f\"{x}\\t{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1be7b2f0-328c-4421-9693-3748bac8cd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenize both inputs and targets\n",
    "def tokenize_fn(batch):\n",
    "    # tokenize the input sequence first\n",
    "    # this populates input_ids, attention_mask, etc.\n",
    "    tokenized_inputs = tokenizer(\n",
    "        batch['inputs'], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels_batch = batch['targets'] # original targets\n",
    "    aligned_labels_batch = []\n",
    "    for i, labels in enumerate(labels_batch):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        aligned_labels_batch.append(align_targets(labels, word_ids))\n",
    "\n",
    "    # recall: the 'target' must be stored in key called 'labels'\n",
    "    tokenized_inputs['labels'] = aligned_labels_batch\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75ceb3-555b-45f4-b777-80640d2883ba",
   "metadata": {},
   "source": [
    "The former function returns input our tokenized inputs, now containing their ids, attention masks, and so forth, but also the aligned labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81edc16a-fbf1-44a9-ba63-447341025540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inputs', 'targets']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# want to remove these from model inputs - they are neither inputs nor targets\n",
    "data[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0459d2e-a339-431a-a45e-eee98fb3e693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fc88c9ef7b4c958e19fc87dcf5da0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b380bb1e1b468092d22f5f2eacbcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = data.map(\n",
    "  tokenize_fn,\n",
    "  batched=True,\n",
    "  remove_columns=data[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9c18ab8-55fe-48e8-921b-46e098acbaab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 15000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e6c15-83c1-4722-ac1b-b6b1e1d5e846",
   "metadata": {},
   "source": [
    "As we see, columns in our dataset are the ones we need now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7264da03-94b6-448e-800d-abe193e2b75f",
   "metadata": {},
   "source": [
    "### Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "258a0767-d829-4874-8e4c-3d569e7f5ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ef3f8a1-9607-45cc-aba1-fea94dcc7bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/11264684/flatten-list-of-lists\n",
    "def flatten(list_of_lists):\n",
    "    flattened = [val for sublist in list_of_lists for val in sublist]\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff3698-bf3e-48b5-8278-28c4358cb0ee",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "Unfortunately, `seqeval` just works for IOB format (which is for NER), so in this case we'll need to compute the metrics manually without using this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52affcd1-6930-44c0-b674-2d6c0215cc88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # remove -100 from labels and predictions\n",
    "    labels_jagged = [[t for t in label if t != -100] for label in labels]\n",
    "\n",
    "    # do the same for predictions whenever true label is -100\n",
    "    preds_jagged = [[p for p, t in zip(ps, ts) if t != -100] \\\n",
    "        for ps, ts in zip(preds, labels)\n",
    "    ]\n",
    "\n",
    "    # flatten labels and preds\n",
    "    labels_flat = flatten(labels_jagged)\n",
    "    preds_flat = flatten(preds_jagged)\n",
    "\n",
    "    acc = accuracy_score(labels_flat, preds_flat)\n",
    "    f1 = f1_score(labels_flat, preds_flat, average='macro')\n",
    "\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bcf3491-664c-4fc9-8797-e8bf62fcd817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6, 'accuracy': 0.8}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [[-100, 0, 0, 1, 2, 1, -100]]\n",
    "logits = np.array([[\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "]])\n",
    "\n",
    "compute_metrics((logits, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5752c01-0164-468f-b758-cadaa44ccf3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f0b4e-9960-4373-a431-c0b1352cb47e",
   "metadata": {},
   "source": [
    "**Note that** we get metrics for each entity, and then overall metrics. \n",
    "**Note 2:** It seems off that ORG precision is 0, even if we did some correct predictions (it should intuitively be 0.5). This is because seqeval does some special computation for ER evaluation (so their evaluation differs from the generic ML one).\n",
    "\n",
    "Let's now write our compute metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d03c651c-64a6-44fb-a333-96ba05833797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # remove -100 from labels and predictions\n",
    "    labels_jagged = [[t for t in label if t != -100] for label in labels]\n",
    "\n",
    "    # do the same for predictions whenever true label is -100\n",
    "    preds_jagged = [[p for p, t in zip(ps, ts) if t != -100] \\\n",
    "        for ps, ts in zip(preds, labels)\n",
    "    ]\n",
    "\n",
    "    # flatten labels and preds\n",
    "    labels_flat = flatten(labels_jagged)\n",
    "    preds_flat = flatten(preds_jagged)\n",
    "\n",
    "    acc = accuracy_score(labels_flat, preds_flat)\n",
    "    f1 = f1_score(labels_flat, preds_flat, average='macro')\n",
    "\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75e87e0f-a3c9-45e5-9d1e-d6025d8df627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6, 'accuracy': 0.8}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [[-100, 0, 0, 1, 2, 1, -100]]\n",
    "logits = np.array([[\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.8, 0.1, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "  [0.1, 0.8, 0.1],\n",
    "]])\n",
    "compute_metrics((logits, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ad633-58fa-4221-be04-acea2f019279",
   "metadata": {},
   "source": [
    "## Model and trainer\n",
    "\n",
    "We'll use AutoModelForTokenClassification, which is accurate for our current task. For this, we need to specify the labels in an alternative way, passing the arguments id2label and label2id, defined based on our input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5982540b-64bd-4ccd-b209-54580b6724bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58404407-29b3-4205-bddd-0882e1f4a56f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"distilbert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc07c722-1d4e-4fb5-b3fd-7fe22fe56508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 03:49, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.946801</td>\n",
       "      <td>0.982971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.052729</td>\n",
       "      <td>0.956710</td>\n",
       "      <td>0.985548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.0669231357574463, metrics={'train_runtime': 233.4162, 'train_samples_per_second': 128.526, 'train_steps_per_second': 16.066, 'total_flos': 387922021634304.0, 'train_loss': 0.0669231357574463, 'epoch': 2.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "185f962d-cfdf-4f03-8992-c1c6c010f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ece62bf-15d6-43d9-b0c9-bd32977d044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "  \"token-classification\",\n",
    "  model='my_saved_model',\n",
    "  device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e70e13d-643d-48d4-8a61-a783ed323786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'NOUN',\n",
       "  'score': 0.9996592,\n",
       "  'index': 1,\n",
       "  'word': 'Bill',\n",
       "  'start': 0,\n",
       "  'end': 4},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.9997565,\n",
       "  'index': 2,\n",
       "  'word': 'Gates',\n",
       "  'start': 5,\n",
       "  'end': 10},\n",
       " {'entity': 'VERB',\n",
       "  'score': 0.9997701,\n",
       "  'index': 3,\n",
       "  'word': 'was',\n",
       "  'start': 11,\n",
       "  'end': 14},\n",
       " {'entity': 'DET',\n",
       "  'score': 0.9998252,\n",
       "  'index': 4,\n",
       "  'word': 'the',\n",
       "  'start': 15,\n",
       "  'end': 18},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.9996026,\n",
       "  'index': 5,\n",
       "  'word': 'CEO',\n",
       "  'start': 19,\n",
       "  'end': 22},\n",
       " {'entity': 'ADP',\n",
       "  'score': 0.9998227,\n",
       "  'index': 6,\n",
       "  'word': 'of',\n",
       "  'start': 23,\n",
       "  'end': 25},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.9993993,\n",
       "  'index': 7,\n",
       "  'word': 'Microsoft',\n",
       "  'start': 26,\n",
       "  'end': 35},\n",
       " {'entity': 'ADP',\n",
       "  'score': 0.9997732,\n",
       "  'index': 8,\n",
       "  'word': 'in',\n",
       "  'start': 36,\n",
       "  'end': 38},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.9998217,\n",
       "  'index': 9,\n",
       "  'word': 'Seattle',\n",
       "  'start': 39,\n",
       "  'end': 46},\n",
       " {'entity': '.',\n",
       "  'score': 0.99977714,\n",
       "  'index': 10,\n",
       "  'word': ',',\n",
       "  'start': 46,\n",
       "  'end': 47},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.9997873,\n",
       "  'index': 11,\n",
       "  'word': 'Washington',\n",
       "  'start': 48,\n",
       "  'end': 58},\n",
       " {'entity': '.',\n",
       "  'score': 0.999481,\n",
       "  'index': 12,\n",
       "  'word': '.',\n",
       "  'start': 58,\n",
       "  'end': 59}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Bill Gates was the CEO of Microsoft in Seattle, Washington.\"\n",
    "pipe(s)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
